{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416764ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddiaz\\OneDrive\\Documentos\\UNIVERSIDAD EUROPEA\\ENTREGABLES\\TFM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Texto 1\n",
       "Nyria alz√≥ el grimorio sobre la piedra r√∫nica, mientras el viento enloquec√≠a a su alrededor y las brasas del bosque encantado se elevaban en espirales anaranjadas. El fuego no quemaba, sino que susurraba nombres olvidados, secretos que dorm√≠an bajo la monta√±a de ceniza. Hab√≠a cre√≠do que su linaje de sangre estaba extinguido, pero el c√≥dice la hab√≠a elegido. Y una vez le√≠do en voz alta, no habr√≠a marcha atr√°s: el Fuego Eterno regresar√≠a."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tu respuesta: ia\n",
      "üß™ Modelo predijo: humano\n",
      "üéØ Realidad: ia\n",
      "‚úÖ Coincide con la clase real.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Texto 2\n",
       "Las civilizaciones antiguas han dejado un impacto profundo en la sociedad moderna, desde las leyes hasta el arte. Mesopotamia nos leg√≥ la escritura, Egipto la arquitectura monumental, Grecia la filosof√≠a y Roma el derecho. Aunque algunas de estas culturas han desaparecido, sus conocimientos siguen presentes en nuestro d√≠a a d√≠a, moldeando nuestra forma de ver el mundo. Sin embargo, la pregunta persiste: ¬øhasta qu√© punto hemos logrado evolucionar sin olvidar nuestras ra√≠ces? La historia no solo debe ser estudiada, sino comprendida para evitar repetir los errores del pasado y fortalecer los logros que nos definen como humanidad."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tu respuesta: humano\n",
      "üß™ Modelo predijo: ia\n",
      "üéØ Realidad: ia\n",
      "‚ùå No coincide con la clase real.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Texto 3\n",
       "Los esc√°ndalos de abusos a menores han sumido al Vaticano en un proceso de purga sin precedentes. Especialmente por la relevancia de los afectados y los niveles a los que est√°n llegando las acusaciones. Ha ca√≠do ya la c√∫pula entera de la jerarqu√≠a eclesial chilena. Luego le toc√≥ al cardenal Theodore McCarrick, a quien el Pont√≠fice retir√≥ la birreta cardenalicia por primera vez en 90 a√±os. Y ahora Francisco ha aceptado la renuncia del arzobispo de Washington, el cardenal Donald Wuerl, de 77 a√±os, salpicado por el tremendo esc√°ndalo del informe de la Fiscal√≠a de Pensilvania (EE UU)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tu respuesta: humano\n",
      "üß™ Modelo predijo: humano\n",
      "üéØ Realidad: humano\n",
      "‚úÖ Coincide con la clase real.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Texto 4\n",
       "El presidente de Colombia, Gustavo Petro, ha exigido explicaciones al Gobierno de Espa√±a por un incidente ocurrido el 17 de mayo en un restaurante de Valencia, donde una familia migrante colombiana fue presuntamente agredida de forma excesiva por agentes de la Polic√≠a Nacional."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tu respuesta: humano\n",
      "üß™ Modelo predijo: humano\n",
      "üéØ Realidad: humano\n",
      "‚úÖ Coincide con la clase real.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† Texto 5\n",
       "La nostalgia no es solo un sentimiento, es tambi√©n una herramienta pol√≠tica. En tiempos de incertidumbre, recurrimos al pasado como refugio: idealizamos lo que fue, simplificamos lo que recordamos. Desde las series que reviven los a√±os ochenta hasta los discursos que prometen ‚Äúvolver a ser grandes‚Äù, la cultura contempor√°nea ha convertido el anhelo del ayer en mercanc√≠a. Este ensayo analiza c√≥mo esa mirada nost√°lgica moldea nuestra forma de votar, consumir y pensar el futuro."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Tu respuesta: ia\n",
      "üß™ Modelo predijo: ia\n",
      "üéØ Realidad: ia\n",
      "‚úÖ Coincide con la clase real.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test de Turing Interactivo - Evaluaci√≥n perceptiva de textos\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Cargar dataset completo con textos y clases (ajustar nombre si es distinto)\n",
    "df = pd.read_csv(\"dataset_final_completo.csv\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # eliminar columnas vac√≠as si las hubiera\n",
    "\n",
    "# Simulaci√≥n de predicciones (si ya tienes predicciones reales, puedes cargarlas)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "# Tokenizador y modelo de BERT\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Funci√≥n para extraer embeddings BERT\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "    return embeddings\n",
    "\n",
    "# Separar datos para simulaci√≥n\n",
    "X = df[\"texto\"]\n",
    "y = df[\"clase\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Obtener embeddings\n",
    "X_train_emb = get_bert_embeddings(X_train.tolist())\n",
    "X_test_emb = get_bert_embeddings(X_test.tolist())\n",
    "\n",
    "# Entrenar modelo\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_emb, y_train)\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "\n",
    "# Preparar DataFrame de prueba\n",
    "resultados = pd.DataFrame({\n",
    "    \"texto\": X_test.reset_index(drop=True),\n",
    "    \"real\": y_test.reset_index(drop=True),\n",
    "    \"pred\": y_pred\n",
    "})\n",
    "\n",
    "# Interfaz interactiva para evaluaci√≥n manual\n",
    "num_muestras = 5  # puedes cambiar este valor\n",
    "df_eval = resultados.sample(n=num_muestras, random_state=1).reset_index(drop=True)\n",
    "\n",
    "for i in range(num_muestras):\n",
    "    display(Markdown(f\"### \\U0001f9e0 Texto {i+1}\\n{df_eval.loc[i, 'texto']}\"))\n",
    "    respuesta = input(\"\\u00bfCrees que este texto es HUMANO o IA? (escribe 'humano' o 'ia'): \").strip().lower()\n",
    "    real = df_eval.loc[i, \"real\"]\n",
    "    pred = df_eval.loc[i, \"pred\"]\n",
    "\n",
    "    print(f\"\\n\\u2705 Tu respuesta: {respuesta}\")\n",
    "    print(f\"\\U0001f9ea Modelo predijo: {pred}\")\n",
    "    print(f\"\\U0001f3af Realidad: {real}\")\n",
    "\n",
    "    if respuesta == real:\n",
    "        print(\"\\u2705 Coincide con la clase real.\")\n",
    "    else:\n",
    "        print(\"\\u274c No coincide con la clase real.\")\n",
    "\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
